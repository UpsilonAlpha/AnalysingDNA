{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCIE3100/BINF7000 Assignment 2\n",
    "\n",
    "## Analysing DNA elements to understand transcriptional regulation\n",
    "---\n",
    "\n",
    "* **Due:** 2pm 22/09/2023\n",
    "* **Revision:** 1 (2023)\n",
    "* **Marks:** 20 (20% of course) \n",
    "\n",
    "### Objectives and assessment\n",
    "\n",
    "Below are a number of exercises that aim to guide you through issues and help you understand concepts related to:\n",
    "* processing genome-wide assays and mapping them to a genome reference sequence\n",
    "* file formats that are used for storing genome-wide data\n",
    "* epigenetic and transcription factor binding data\n",
    "* transcriptome data to determine gene expression across developmental samples\n",
    "* approaches to understand transcriptional regulation\n",
    "\n",
    "### Format\n",
    "\n",
    "This assignment consists of two parts, each containing a number of problems of the two types discussed below. You are expected to work you way through this over a number of weeks in practicals and in your own time, supported by topics covered in course materials and tutorials. You are also able to interact with tutors in practicals and your fellow class mates.\n",
    "\n",
    "The assignment has a series of “A” problems to which short responses are assessed. Some responses are fixed-format and automatically marked as either correct (pass) or not (fail); these can be attempted multiple times before a final submission. Other responses are evaluated by a marker, after the submission. Solutions to “A” problems are based on individual work (such as research and experimentation, involving programming, data processing/analysis and interpretation) and submitted via Coder Quiz. Solutions are provided for several <span style=\"color:blue\">*example questions.*</span> These are intended to demonstrate how you can interact with the various datatypes used in this assignment, and are **not** associated with any marks.\n",
    "\n",
    "The assignment has a section with one or more open-ended “C” problems for which a report is submitted and assessed. Solutions to “C” problems involve individual contributions and collaborative work via coordinated group work. The report is submitted via Blackboard by the group and must contain a disclosure statement, identifying all contributors and their corresponding contributions.\n",
    "\n",
    "Here's an example of such a disclosure:\n",
    "\n",
    "*This report is in its entirety the result of the work of A.B., C.D. and E.F. A.B. and C.D. identified the relevant literature, and defined the problem approached. E.F. curated and described data sets, and A.B. and E.F. wrote the code for analysis. C.D. wrote Introduction. E.F. collected and plotted results and wrote Results. A.B., C.D. and E.F. wrote equal parts of Discussion and endorsed the report. A.B. and E.F. contributed the same amount of work, C.D. worked more, at rates 0.9, 0.9 and 1.2, respectively, summing to 3 (mean 1).*\n",
    "\n",
    "The length of the report should not exceed 5 pages (roughly 1 page introduction with problem, 1 page data set and method, 2 pages with results (including tables and figures), 1 page with discussion, disclosure and references).\n",
    "We recommend that the report uses bullet points for clear messaging and figures to display results and comparisons.\n",
    "\n",
    "### Marking\n",
    "\n",
    "The assignment is worth 20% of the course, marked out of 20 marks. \n",
    "\n",
    "Marks are awarded as per the schedule below.\n",
    "\n",
    "#### “A” problems (10 marks total)\n",
    "\n",
    "| Marks | Criteria |\n",
    "| ----- | -------- |\n",
    "| 0 – 10| In proportion to number of *correct* responses|\n",
    "\n",
    "Marks are given for <span style=\"color:red\">*auto-marked, fixed-format questions*</span>, and for <span style=\"color:green\">*short text questions*</span>; each type is indicated by red and green high-lighting (respectively) below. Note that it is *not* sufficient to attempt a question to get a mark. In addition, you are required to submit the code you use for some questions (further details below). \n",
    "\n",
    "#### “C” problems (sum of two parts $\\Sigma$, then multiplied by $\\eta$, which is a factor with mean 1, capped at 10 marks; $\\eta$ is used to account for uneven member contributions as evidenced by disclosure statement)\n",
    "| Mark\t| Criteria |\n",
    "| ----- | -------- |\n",
    "| 0 – 2\t| Report is poorly presented, the work as a whole is unclear, and individual contributions are not disclosed adequately |\n",
    "| 3 – 4\t| Report presents a study that answers one or more questions, but evidence is tentative, or unclear; contributions are disclosed properly |\n",
    "| 5 – 6\t| Report clearly presents a study that answers one or more questions, with indisputable evidence in support; contributions are disclosed properly |\n",
    "|    +  | |\n",
    "| 0 – 1\t| Scientific problem is well defined (yes 1, no 0) |\n",
    "| 0 – 1\t| Data set/s and method/s are well described and implemented (yes 1, no 0) |\n",
    "| 0 – 1\t| Results are clearly tabulated and/or visualised (yes 1, no 0) |\n",
    "| 0 – 1\t| Conclusion puts results in a scientific context (yes 1, no 0) |\n",
    "| = $\\Sigma \\cdot \\eta$ | $\\eta$ is a group member contribution factor with a group mean 1 |\n",
    "\n",
    "Formative feedback on submissions should be actively sought in the timetabled practical and tutorial sessions from course staff. Awarded marks will be published on Blackboard Grade Centre.\n",
    "\n",
    "### Workflow and submission\n",
    "\n",
    "You should submit responses to \"A\" problems to [Coder Quiz](https://coderquiz.scmb.uq.edu.au/). You may submit as many times as you would like to Coder Quiz, and your last response before the due date will be graded. You are also required to submit code for questions A7-A9. Place all required code in a *single* `.py` file and submit via the separate Coder Quiz link. Ensure that individual questions are labeled clearly and that the code is well commented. It does **not** need to run.\n",
    "\n",
    "You should submit your group's responses to \"C\" problems as a report through Blackboard/Turnitin. Only one submission for each group will be accepted.\n",
    "\n",
    "The discussion board is available if you want to engage in or need a broader discussion on a topic/question relevant to the assignment. That said, your individual submission must be the result of *your* understanding, and the group submission must be based in its entirety on the work of the members of the group; if your answer contains anything that you are unable to explain or reproduce without the help of somebody else, you *must* acknowledge this. There is a separate field in Coder Quiz to list posts on the discussion board that you have done, and posts that you have benefitted from. (In Ed Discussion, \"... / Copy Link\" for each such post.) The report's disclosure statement should declare benefits you have acquired from consulting with external parties, via the discussion board or other interactions, oral or written.\n",
    "\n",
    "### Resources\n",
    "\n",
    "* Weekly notebooks for weeks 5 and 7 (on Blackboard). Thes introduced many of the concepts covered in this assessment.\n",
    "* Quick link to [How-to install binfpy](#howto_install_binfpy).\n",
    "* The UQ Bioinformatics Python Guide (on Blackboard)\n",
    "* The [Python 3 documentation]. For those unfamiliar with Python the [official tutorial] is recommended\n",
    "* The Software Carpentry [novice Python lessons]\n",
    "* [IPython's own notebook tutorial](http://nbviewer.jupyter.org/github/ipython/ipython/blob/3.x/examples/Notebook/Index.ipynb)\n",
    "* [Markdown cheatsheet] (Markdown is the syntax you use to write formatted text into cells in a notebook.)\n",
    "\n",
    "[Python 3 documentation]: https://docs.python.org/3/\n",
    "[official tutorial]: https://docs.python.org/3/tutorial/index.html\n",
    "[novice python lessons]: http://swcarpentry.github.io/python-novice-inflammation/\n",
    "[Markdown cheatsheet]: https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet\n",
    "\n",
    "### Important: Python version information\n",
    "\n",
    "Certain updates in recent Python versions (3.9 onwards) have caused incompatibilities with the `twobit.py` module. **Please ensure you are running Python 3.8 or earlier when completing Part A of this assignment.**\n",
    "\n",
    "### Relevant code\n",
    "* `twobit.py` Read full genome sequences on the .2bit format\n",
    "* `bed.py` and `ival.py` File formats for genome wide data; methods for reading and extracting data\n",
    "* `sym.py` References to the DNA alphabet\n",
    "* `sequence.py` Biological sequence processing; sequence motifs\n",
    "* `prob.py` Probability distributions\n",
    "* `gtf.py` File format for reading and extracting genome annotation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick-links\n",
    "1. [Analysing genome data](#Exercise1) \n",
    "2. [Gene expression](#Exercise2) \n",
    "3. [Chromatin accessibility](#Exercise3) \n",
    "4. [Project](#Exercise4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "def print_msg(msg_lst: list, sep='\\t', color='\\033[91m'):\n",
    "    msg = \"\"\n",
    "    for i in msg_lst:\n",
    "        msg += str(i) + sep\n",
    "\n",
    "    print(color + \"-\" * 80 + bcolors.ENDC)\n",
    "    print(color + msg.center(80, ' ') + bcolors.ENDC)\n",
    "    print(color + '-' * 80 + bcolors.ENDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('path to binfpy')     # If binfpy is not already in your PYTHONPATH\n",
    "import sym      # we are going to make reference to sequence alphabets\n",
    "import sequence # for constructing sequences from genome reference data\n",
    "import twobit   # for reading genome reference sequence data\n",
    "import bed      # for processing files on the BED format\n",
    "import prob     # for motif data\n",
    "import rcdict   # dictionary of DNA sequence, which does not distinguish between strands\n",
    "import gtf      # for reading genome annotation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be using `numpy` and `matplotlib`, so those standard libraries need to be imported too. We suggest that you make matplotlib plot its plots `\"in-line\"` so that visual results are available in the same notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Exercise1\"></a>\n",
    "## Part 1: Analysing different types of genomic data\n",
    "\n",
    "Before getting to the exercises we need to gain access to and understand three biologically different types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological data type I: Genome reference data\n",
    "The portal for the UCSC Genome Browser (http://genome.ucsc.edu) contains the reference sequence and working draft assemblies for a large collection of genomes. We will use the 2009 assembly for human, also referred to as hg19.\n",
    "\n",
    "The human genome is large (3Gb) so we will use a compressed format known as ‘2bit’ where each base is represented by 2 ‘bits’. Caution: the file is about 800MB. You can also download it using the link below. Make sure you save the file in the notebook directory (or remember to reference it by the directory where you put it).\n",
    "\n",
    "http://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.2bit\n",
    "\n",
    "Fire up Python and use the module `twobit.py` to have a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19 = twobit.TwoBitFile('hg19.2bit')  # assumes that the genome is stored in your current directory\n",
    "for key in hg19:\n",
    "    if len(hg19[key]) > 5000050:\n",
    "        print(key)\n",
    "        print(hg19[key][5000000:5000050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Python hg19 is a dictionary. The for-loop will show you the main pieces that make up the genome. No prizes for guessing what they correspond to… You can access each chromosome separately, but be careful not to print the actual sequence unless you provide a ‘genome location index’ or ‘range’, as exemplified below. You now have every single base in the human (reference) genome at your fingertips! \n",
    "\n",
    "Try to understand what the following three lines actually mean as you execute them. No need to write it down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19['chrX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hg19['chrX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19['chrX'][1000000:1000060]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage you should realise why **you should *not* do this**:\n",
    "```python\n",
    "print(hg19['chrX'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological data type II: Gene annotation data\n",
    "\n",
    "Later we will need to know where genes are placed in the human reference genome, in particular where their transcription start sites are located. \n",
    "\n",
    "The UCSC Genome website has a ‘Table browser’ where you can download various, customisable genomic datasets. You are provided with two for this assignment. `hum_TSS.bed` contains the coordinates of the transcription start site TSS for 'known genes' of the human genome. Technically, we selected 1 bp upstream, as entries must have a length of at least 1. Entries in `hum_prom.bed` instead represent the region 1000 bp upstream of the TSS. This distance is commonly used to approximate the promoter of a gene. \n",
    "\n",
    "Familiarise yourself with the BED format. You can look at the file in a normal text editor. `bed.py` has functionality to process the data too. Each entry describes a genomic region. Notice that the most basic entry has three fields, namely *Chromosome*, *start locus*, and *end locus*. More complicated variants will annotate a region with additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = bed.BedFile('hum_TSS.bed', 'Optional')\n",
    "print('The BED file has this many entries:', len(tss))\n",
    "cnt = 0\n",
    "for e in tss:\n",
    "    if \"uc002iwu.3\" in e.name:\n",
    "        cnt += 1 \n",
    "        print(e.name)\n",
    "        break\n",
    "print('The chromosome of that final entry is:', e.chrom)\n",
    "print('The start site of that final entry is:', e.chromStart)\n",
    "print('The end site of that final entry is:', e.chromEnd)\n",
    "print('More info on this entry: strand is', e.strand, 'and name is', e.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological data type III: Epigenetic, histone modification data\n",
    "The Encyclopedia of DNA Elements (ENCODE; https://www.encodeproject.org) Consortium is an international collaboration of research groups funded by the National Human Genome Research Institute (NHGRI). The goal of ENCODE is to build a comprehensive parts list of functional elements in the human genome, including elements that act at the protein and RNA levels, and regulatory elements that control cells and circumstances in which a gene is active.\n",
    "\n",
    "ChIP-seq has been used extensively by ENCODE to determine where transcription factors bind, and where chromatin modifications and other major protein-DNA binding events occur. \n",
    "\n",
    "Histone-3 Lysine-4 tri-methylation (H3K4me3) is known as an active promoter mark. Histone-3 Lysine-27 acetylation (H3K27ac) is regarded as an active transcription, and mostly enhancer mark. \n",
    "\n",
    "From the ENCODE page, you can search and view ChIP-seq experiments for human embryonic stem cells (hESC). So-called ‘broadPeak’ files for the mentioned modifications, and many others, are available. For the purposes of this assignment, `H3K4me3.bed` and `H3K27ac.bed` have been downloaded and are in your directory.\n",
    "\n",
    "You can use `bed.py` to load and use these broadPeak files. For example, you may want to find the H3K4me3 peak that is closest to a specific transcription start site; `bed.py` has a function `getClosest` and a function `getOneOfClosest` which will find the peaks that are closest when we measure the minimum distance from one end of an entry to the end of the other, i.e. the minimum boundary-to-boundary distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3k4me3 = bed.BedFile('H3K4me3.bed')\n",
    "print(h3k4me3.getOneOfClosest(e))  # one of the closest BED entry in h3k4me3\n",
    "for h in h3k4me3.getClosest(e):    # could be several closest BED entry in h3k4me3 (with identical distances)\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Which is at a boundary-to-boundary distance of ' + str(bed.dist(e,h)) + ' base pairs')\n",
    "print('Which is at a centre-to-centre distance of ' + str(bed.dist(e,h,centre2centre=True)) + ' base pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We similarly load the H3K27ac peaks. For fun, we illustrate the use of the function `getOneOfOverlap` in `bed.py` to determine how many of the H3K27ac peaks overlap with H3K4me3 peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3k27ac = bed.BedFile('H3K27ac.bed')\n",
    "cnt = 0\n",
    "for mark in h3k27ac:\n",
    "    if h3k4me3.getOneOfOverlap(mark) != None:\n",
    "         cnt += 1\n",
    "print('Found', cnt, 'H3K27ac peaks of a total', len(h3k27ac), 'overlapped with H3K4me3 peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mark in h3k27ac:\n",
    "    if h3k27ac.getClosest(mark) != None:\n",
    "        for h in h3k27ac.getClosest(mark):    # could be several closest BED entry in H3K27ac (with identical distances)\n",
    "            print(h)\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run through the following examples. Make sure you understand what each line of code is doing, and the biological context of the problems.\n",
    "\n",
    "<span style=\"color:blue\">**Example problem: To two decimal places, what percentage of transcripts have a H3K4me3 mark overlapping their promoter region (1000bp upstream of the TSS)?** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h3k4me3 = []\n",
    "\n",
    "proms = bed.BedFile('hum_prom.bed')\n",
    "\n",
    "for prom in proms:\n",
    "    closest_mark = h3k4me3.getOneOfOverlap(prom)\n",
    "    if closest_mark is not None:\n",
    "        d_h3k4me3.append(bed.dist(prom, closest_mark, centre2centre = True))\n",
    "    \n",
    "print(f'Mean distance is: {np.mean(d_h3k4me3)}')\n",
    "print(f'Percentage of genes is: {round(len(d_h3k4me3)/len(proms)*100, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Example problem: To two decimal places, what is the mean centre-to-centre log-transformed distance between H3K4me3 marks and their closest gene, when measured to the gene's TSS? Produce a mean and a distribution of distances.** </span>\n",
    "\n",
    "Note that we use `getOneOfClosest` to determine the closest gene, even though it uses the boundary-to-boundary distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h3k4me3 = []\n",
    "closest_tss_count = {}\n",
    "\n",
    "for mark in h3k4me3:\n",
    "    closest_TSS = tss.getOneOfClosest(mark) # Gets the closest TSS\n",
    "    d_h3k4me3.append(math.log10(bed.dist(mark, closest_TSS, centre2centre = True)+1))\n",
    "    \n",
    "plt.figure(1, figsize=(8,8))\n",
    "ax = plt.axes([0.1, 0.1, 0.8, 0.8])\n",
    "n, bs, ps = plt.hist(d_h3k4me3, 100, density=1, color='g', histtype = 'step')\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean log-transformed distance is: {round(np.mean(d_h3k4me3), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Example problem: To two decimal places, what is the mean log-transformed distance between H3K27ac marks and their closest gene (TSS)? Produce a mean and a distribution of distances.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h3k27ac = []\n",
    "for mark in h3k27ac:\n",
    "    closest_TSS = tss.getOneOfClosest(mark)\n",
    "    d_h3k27ac.append(math.log10(bed.dist(mark, closest_TSS, centre2centre = True)+1))\n",
    "\n",
    "plt.figure(1, figsize=(8,8))\n",
    "ax = plt.axes([0.1, 0.1, 0.8, 0.8])\n",
    "n, bs, ps = plt.hist(d_h3k27ac, 100, density=1, color='r', histtype = 'step')\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean log-transformed distance is: {round(np.mean(d_h3k27ac), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Consider the information provided above about known roles of these histone modifications. Are the plots we generated consistent with this?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Exercise2\"></a>\n",
    "## Part 2: Gene expression\n",
    "\n",
    "You are now going to analyse sequence data taken from a dataset of human cortical organoids, which are in vitro models of the developing human cortex. Essentially these are 3-dimensional regions of the human brain that have been grown in culture from human pluripotent stem cells (hPSCs), which are then manipulated to differentiate into embryonic stem cells (ESCs) then human cortical organoids (hCOs). Other brain areas can also be grown using this method!\n",
    "\n",
    "The use of organoids for developmental research is still a relatively new research technique but has been adopted as an alternative model for studying brain development because of the ability to generate multiple brain tissue samples from a single batch of hPSCs. However, for organoids to be an effective model they should simulate features of the in vivo versions of these tissues. This is one of the goals of the paper below that we will analyse datasets from: Xiang et al. \"Fusion of regionally specified hPSC-derived organoids model human brain development and interneuron migration\" (2017) Cell Stem Cell 21:383-398.\n",
    "\n",
    "This study contains multiple dataset types that were analysed in an intergrated way to understand the overall patterns of molecular development in the human brain. In this practical we will focus on the bulk RNA-seq and ATAC-seq datasets of two developmental stages: ESC stage and hCO day 72 stage, in part 2 and part 3, respectively. These samples can be found in the NCBI GEO repository, data series GSE97881 (RNA-seq, samples GSM2579553 & GSM2579557) and GSE97880 (ATAC-seq, samples GSM2579550 & GSM2579552)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 2, we will analyse the RNA-seq datasets. Raw sequencing data is aligned to the human genome reference **hg19** and the number of reads mapped to each reference transcript counted. The count data is normalised for each sample using the size of the cDNA library. These first two steps have already been done and we will start with this count data. Following this we will calculate the RPKM measure of gene expression (Reads Per Kilobase Million), filter out transcripts with low expression, then calculate fold change of expression across the hCO day 72 and ESC samples.\n",
    "\n",
    "Before we start analysing the count data, we will first create a dictionary of all hg19 transcript data derived from a subset of the hg19 genome GTF annotation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19gtf_tx = gtf.GtfFile('hg19_transcripts.ncbiRefSeq.gtf') # GTF subset for transcripts only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19tx = dict()\n",
    "for entry in hg19gtf_tx.__iter__():\n",
    "    group = entry.group\n",
    "    items = group.strip(';').split('; ')\n",
    "    item_dict = dict()\n",
    "    for item in items:\n",
    "        info = item.split()\n",
    "        item_dict[info[0]] = info[1].strip('\"')\n",
    "    if '_' in item_dict['transcript_id'][3:]:\n",
    "        hg19tx[item_dict['transcript_id'].strip('\"')[:-4]] = [item_dict['gene_id'], entry.seqname,\n",
    "                                                              entry.start, entry.end, entry.__len__()]\n",
    "    elif '_' not in item_dict['transcript_id'][3:]:\n",
    "        hg19tx[item_dict['transcript_id'].strip('\"')[:-2]] = [item_dict['gene_id'], entry.seqname, \n",
    "                                                              entry.start, entry.end, entry.__len__()]\n",
    "    else:\n",
    "        hg19tx[item_dict['transcript_id'].strip('\"')] = [item_dict['gene_id'], entry.seqname, \n",
    "                                                         entry.start, entry.end, entry.__len__()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hg19tx.keys()))\n",
    "dict(list(hg19tx.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of sample data\n",
    "esc = open('ESC_isoforms_results.txt', 'r')\n",
    "hCO_day72 = open('hCO_day72_isoforms_results.txt', 'r')\n",
    "\n",
    "esc_exp = dict()\n",
    "esc_count = []\n",
    "for i,r in enumerate(esc):\n",
    "    row = r.strip('\\n').split('\\t')\n",
    "    if i >= 1:\n",
    "        esc_exp[row[0]] = [row[1], int(row[2])]\n",
    "        esc_count.append(int(row[2]))\n",
    "print('Number of isoforms detected (non-zero expression) in ESC sample is:', sum(x > 0 for x in esc_count))\n",
    "print('Total number of reads in ESC sample is:', sum(esc_count))\n",
    "\n",
    "hCO_exp = dict()\n",
    "hCO_count = []\n",
    "for i,r in enumerate(hCO_day72):\n",
    "    row = r.strip('\\n').split('\\t')\n",
    "    if i >= 1:\n",
    "        hCO_exp[row[0]] = [row[1], int(row[2])]\n",
    "        hCO_count.append(int(row[2]))\n",
    "print('Number of isoforms detected (non-zero expression) in hCO day 72 sample is:', sum(x > 0 for x in hCO_count))\n",
    "print('Total number of reads in hCO day72 sample is:', sum(hCO_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RPKM values in ESC sample\n",
    "esc = open('ESC_isoforms_results.txt', 'r')\n",
    "for i,r in enumerate(esc):\n",
    "    row = r.strip('\\n').split('\\t')\n",
    "    if i >= 1:\n",
    "        rpm = int(row[2])/(sum(esc_count)/1000000)\n",
    "        rpkm = rpm/(hg19tx[row[0]][4]/1000)\n",
    "        esc_exp[row[0]].append(round(rpkm,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RPKM values in hCO day 72 sample\n",
    "hCO_day72 = open('hCO_day72_isoforms_results.txt', 'r')\n",
    "for i,r in enumerate(hCO_day72):\n",
    "    row = r.strip('\\n').split('\\t')\n",
    "    if i >= 1:\n",
    "        rpm = int(row[2])/(sum(hCO_count)/1000000)\n",
    "        rpkm = rpm/(hg19tx[row[0]][4]/1000)\n",
    "        hCO_exp[row[0]].append(round(rpkm,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See results for one Refseq\n",
    "print(esc_exp['NM_013375'])\n",
    "print(hCO_exp['NM_013375'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Assignment question A1: Filter low RPKM transcripts for hCO and report the number of transcripts that are *shared* between the filtered ESC and hCO samples.**\n",
    "    \n",
    "In the code below we show an example removing transcripts with RPKM < 0.01 for hCO. Perform the same process for ESC, then identify transcripts that are present in both datasets (common_exp).\n",
    "                                                                          \n",
    "Tip: to help with subsequent questions, you can setup common_exp with Refseq IDs as keys, and a list as the corresponding value that you can add values to such as gene name and counts from each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example removing low RPKM transcripts (RPKM < 0.01) for hCO. An additional hCO_low_exp dictionary is made \n",
    "# to keep the transcripts that are filtered out. This will be used in Part 3.\n",
    "hCO_exp_filter = dict()\n",
    "hCO_exp_low = dict()\n",
    "for transcript in hCO_exp.keys():\n",
    "    if hCO_exp[transcript][2] >= 0.01:\n",
    "        hCO_exp_filter[transcript] = hCO_exp[transcript]\n",
    "    else:\n",
    "        hCO_exp_low[transcript] = hCO_exp[transcript]\n",
    "\n",
    "print(len(hCO_exp_filter), 'transcripts in hCO day 72 sample passed the filtering')\n",
    "\n",
    "# Repeat the process of removing low RPKM transcripts for ESC\n",
    "\n",
    "\n",
    "# ---------------------- Write your code here\n",
    "\n",
    "\n",
    "# Then find overlap of common transcripts in both filtered samples\n",
    "common_exp = dict() # A dictionary to store the shared genes in\n",
    "\n",
    "# ---------------------- Write your code here\n",
    "\n",
    "print('There are', len(common_exp), 'transcripts common to both filtered samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Assignment question A2: Compute log fold expression changes for all transcripts which passed RPKM filtering in both samples. Report the *gene* names corressponding to the top 10 differentially expressed transcripts.**\n",
    "    \n",
    "Tips:\n",
    "* Log fold change refers to log2 ratio of gene expression between samples (use `math.log2`).\n",
    "* We care only about the magnitude - not the direction - of expression changes.\n",
    "* Each transcript ID maps to a gene name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each transcript is associated with a singe gene, however many transcripts may map to the same gene due to the presence of isoforms. For instance, the gene associated with the most differentially expressed transcript (identified in the previous question) has seven isoforms with RPKM > 0.01 in both samples.\n",
    "\n",
    "<span style=\"color:red\">**Assignment question A3: Report the absolute log fold change for each of these seven isoforms correct to 2 decimal places.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marker genes\n",
    "\n",
    "One way to assess the quality of a dataset is to examine the expression of marker genes. In the following example, we will look at the expression of genes that are known to be markers of a neuronal progenitor cells, that is, genes that are up-regulated once the cells progress beyond stem cells and begin to take on a neuronal phenotype. This means we would expect them to be more highly expressed in the hCO sample compared to the ESC sample. \n",
    "\n",
    "For genes in the 'markers' list below show the log fold change for all isoforms for each gene:\n",
    "```    \n",
    "['PAX6', 'NEUROG2', 'TBR1', 'BCL11B', 'SLC32A1', 'GAD1', 'GAD2','GFAP', 'GLUD1', 'SLC17A7', 'SLC17A6']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['PAX6', 'NEUROG2', 'TBR1', 'BCL11B', 'SLC32A1', 'GAD1', 'GAD2', \n",
    "           'GFAP', 'GLUD1', 'SLC17A7', 'SLC17A6']\n",
    "marker_dict = dict()  # use to store isoforms\n",
    "for gene in markers: \n",
    "    marker_dict[gene] = []\n",
    "\n",
    "    \n",
    "# ---------------------- Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Assignment question A4: Which marker gene showed bidirectional changes (up- and down-regulated) across their isoforms?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate this further, we can examine how the isoform exon sequences vary using an exon subset of the hg19 GTF annotation file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Assignment question A5: What is the major difference between the isoforms for the gene identified in A4? Look at the number and genomic range of the exons.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19gtf_ex = gtf.GtfFile('hg19_exons_subset.ncbiRefSeq.gtf') # GTF subset of 100K exons\n",
    "\n",
    "# The below code may provide some hints on how to approach this question\n",
    "\n",
    "for entry in hg19gtf_ex.__iter__():\n",
    "    print(entry.attr) #entry information \n",
    "    print(entry.seqname) # chrom\n",
    "    print(entry.start) # start\n",
    "    print(entry.end) # end\n",
    "    break\n",
    "# ---------------------- Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Exercise3\"></a>\n",
    "## Part 3: Chromatin accessibility\n",
    "\n",
    "You are now going to analyse chromatin accessilibity data generated using ATAC-seq that were performed on the same sample types in the Xiang et al paper alongside the RNA-seq analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATAC-seq data quality assessment\n",
    "\n",
    "To assess the quality of the ATACseq data, we will be looking at alignment files that are typically stored in SAM or BAM file (BAM is binary version of SAM) that is used to represent aligned sequences (reads). Each line in SAM file corresponds to a single read. The full explanation of this file format is given here, but not required for this exerise: https://www.samformat.info/sam-format-flag\n",
    "\n",
    "For this exercise we will only be focusing on the following fields:\n",
    "* FLAG - this flag provides a description of the read: whether the read is mapped (aligned to genome), the orientation of the read, whether the read pair is mapped, and so on.\n",
    "* RNAME - reference name (chr1, chr2 etc)\n",
    "* POS - chromosomal start position of the alignment\n",
    "* TLEN - template length\n",
    "\n",
    "\n",
    "We will start by loading a subset of the BAM file that contains RNAME (aka chrom), POS and TLEN information. The subsetting was performed on the command line using the samtools package with the following command:\n",
    "`samtools view -f67 ATAC_ESC.bam chr14 | cut -f 3-4,9 > ATAC_ESC_chr14_tlen.txt`\n",
    "For the purpose of this exercise we subset information for 'chr14' only. Using `-f67` option we subset reads that that are first in pair (read 1) and both reads in pair have to be mapped (aligned). https://broadinstitute.github.io/picard/explain-flags.html\n",
    "\n",
    "&nbsp; \n",
    "&nbsp; \n",
    "\n",
    "First, let's load the subset data from the BAM file as a 'cropped' bed file with 3 columns (chrom, start and tlen, represented as 'score'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATAC_esc_bed = bed.BedFile('ATAC_ESC_chr14_tlen.bed','Cropped')\n",
    "ATAC_hCO_bed = bed.BedFile('ATAC_hCO_day72_chr14_tlen.bed','Cropped')\n",
    "print('Head of ESC ATAC results:')\n",
    "for i,e in enumerate(ATAC_esc_bed):\n",
    "    print(e.chrom, e.chromStart, e.score) #score value represents tlen\n",
    "    if i >10:\n",
    "        break\n",
    "print('\\n' + 'Head of hCO day 72 ATAC results:')   \n",
    "for i,e in enumerate(ATAC_hCO_bed):\n",
    "    print(e.chrom, e.chromStart, e.score) #score value represents tlen\n",
    "    if i >10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Example problem: Report the mean and standard deviation of template lengths, each to two decimal places**\n",
    "    \n",
    "Think about whether this was a successful experiment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_msg(['This is an example answer to the question :)'], color=bcolors.OKBLUE)\n",
    "\n",
    "values =[]\n",
    "for i,e in enumerate(ATAC_hCO_bed):\n",
    "    values.append(abs(e.score))\n",
    "    \n",
    "print(np.mean(values))\n",
    "print(np.var(values)/len(values))\n",
    "\n",
    "tlens=[]\n",
    "for e in ATAC_esc_bed:\n",
    "    tlen = abs(e.score) #converting tlen to absolute number\n",
    "    if tlen < 1000: # only focus on reads with tlen < 1000 bases\n",
    "        tlens.append(tlen)\n",
    "\n",
    "plt.hist(tlens, bins=200) \n",
    "plt.ylabel('Read count')\n",
    "plt.xlabel('Fragment Length (bases)')\n",
    "plt.title('ATAC ESC')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(tlens, bins=200, log=True) \n",
    "plt.ylabel('Read count')\n",
    "plt.xlabel('Fragment Length (bases)')\n",
    "plt.title('ATAC ESC log-transformed')\n",
    "plt.show()\n",
    "\n",
    "tlens=[]\n",
    "for e in ATAC_hCO_bed:\n",
    "    tlen = abs(e.score) #converting tlen to absolute number\n",
    "    if tlen < 1000: # only focus on reads with tlen < 1000 bases\n",
    "        tlens.append(tlen)\n",
    "\n",
    "plt.hist(tlens, bins=200) \n",
    "plt.ylabel('Read count')\n",
    "plt.xlabel('Fragment Length (bases)')\n",
    "plt.title('ATAC hCO')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(tlens, bins=200, log=True) \n",
    "plt.ylabel('Read count')\n",
    "plt.xlabel('Fragment Length (bases)')\n",
    "plt.title('ATAC hCO log-transformed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATAC-seq peak analysis\n",
    "\n",
    "Now we will load ATAC-seq peak data from Xiang et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc_atac = bed.BedFile('GSM2579550_ESC_ATAC_peak.bed')\n",
    "hCO_atac = bed.BedFile('GSM2579552_hCO_day72_ATAC_peak.bed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Assignment question A6: How many peaks in the ESC sample overlap peaks in the hCO day 72 sample?**\n",
    "\n",
    "Tips:\n",
    "* Use the `getOneOfOverlap` method.\n",
    "* You will want to use the common overlapping peaks identified here in future sections, so we recomend building a list of common peaks between the files and then using the function `bed.BedFile(common_peaks)`.\n",
    "    * Use the ESC peak to represent the overlap in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_peaks = []\n",
    "\n",
    "# ---------------------- Write your code here\n",
    "\n",
    "common_peaks_bed = bed.BedFile(common_peaks)\n",
    "\n",
    "print(f'{len(common_peaks)} of total {len(esc_atac)} peaks in ESC sample are also found in hCO day 72 sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For questions A7-A9, provide the code you write in a single .py file. Submit this file to the separate link on Coder Quiz.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Assignment question A7: Identify any overlaps between common peaks and the promoter regions of transcripts from aformentioned cortical marker genes. Report a list of marker genes with overlaps.**\n",
    "     \n",
    "First, you'll need to run this code to set up our hg19tx dictionary, this time with some extra information about transcripts' strandedness. Consider why we need to consider the strand on which a given transcript is encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19gtf_tx = gtf.GtfFile('hg19_transcripts.ncbiRefSeq.gtf') # GTF subset for transcripts only\n",
    "hg19tx = dict()\n",
    "for entry in hg19gtf_tx.__iter__():\n",
    "    group = entry.group\n",
    "    items = group.strip(';').split('; ')\n",
    "    item_dict = dict()\n",
    "    for item in items:\n",
    "        info = item.split()\n",
    "        item_dict[info[0]] = info[1].strip('\"')\n",
    "    if '_' in item_dict['transcript_id'][3:]:\n",
    "        hg19tx[item_dict['transcript_id'].strip('\"')[:-4]] = [item_dict['gene_id'], entry.seqname,\n",
    "                                                              entry.start, entry.end, entry.__len__(), \n",
    "                                                             entry.strand]\n",
    "    elif '_' not in item_dict['transcript_id'][3:]:\n",
    "        hg19tx[item_dict['transcript_id'].strip('\"')[:-2]] = [item_dict['gene_id'], entry.seqname, \n",
    "                                                              entry.start, entry.end, entry.__len__(), \n",
    "                                                             entry.strand]\n",
    "    else:\n",
    "        hg19tx[item_dict['transcript_id'].strip('\"')] = [item_dict['gene_id'], entry.seqname, \n",
    "                                                         entry.start, entry.end, entry.__len__(), \n",
    "                                                         entry.strand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, we can access the information about a given transcript simply as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg19tx['NM_001131019']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BED entry objects can be made and annotated with further information as follows. Specifically, this example creates a promoter entry for a transcript encoded on the negative strand, and annotates it with information capturing both the gene name and transcript ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_id = 'NM_001131019'\n",
    "gene_name = hg19tx['NM_001131019'][0]\n",
    "entry = bed.BedEntry(hg19tx[transcript_id][1], hg19tx[transcript_id][3], hg19tx[transcript_id][3]+1000)\n",
    "entry.addOption(name = str(gene_name + ' ' + transcript_id))\n",
    "print(entry.name+'\\t'+str(entry.chromStart)+'\\t'+str(entry.chromEnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create a BedFile for genomic ranges of 1kb upstream promoter region of each transcript, taking into account\n",
    "# the strand on which each transcript is encoded\n",
    "\n",
    "marker_overlaps = []\n",
    "\n",
    "\n",
    "# ---------------------- Write your code here\n",
    "\n",
    "\n",
    "marker_overlaps_bed = bed.BedFile(marker_overlaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Assignment question A8: For the transcripts you identified in A7, compute the log10 distance between the transcription start site (TSS) and the centre of the overlapping ATAC-seq peak. Report the smallest log10 distance you find to two decimal places.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ---------------------- Write your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Problem A9: Of the 1000 most upregulated genes in the hCO sample, how many have ATAC-seq peaks overlapping their promoter region?**\n",
    "    \n",
    "Produce a mean and a distribution of distances (this will help your understanding but is not marked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Write your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to submit your code for questions A7, A8 and A9 to Coder Quiz in addition to your answers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Exercise4\"></a>\n",
    "## Part 4: Group Project\n",
    "\n",
    "### Problem C1\n",
    "\n",
    "Investigate the predictive power of DNA methylation as compared with RNA-seq, in terms of classifying patient samples as either \"Primary Tumor\" or \"Solid Tissue Normal\". \n",
    "\n",
    "The primary question is: Which data type \"performs\" better? We will provide each group with a cancer dataset (there may be a few groups with similar datasets). \n",
    "\n",
    "You will need to train two machine learning models: 1 on DNA methylation data, and 1 on gene expression data (it can be the same model/architecture just trained on different data). Your report will investigate which of the two models performed better.\n",
    "\n",
    "#### Each group will have 2 sets of data from a **specific tissue** with:\n",
    "1. Gene expression data for samples along with a label of either \"Solid Tissue Normal\" or \"Primary Tumor\"\n",
    "2. DNA methylation beta values for samples along with a label of either \"Solid Tissue Normal\" or \"Primary Tumor\"\n",
    "\n",
    "#### A shared mystery dataset will also be available\n",
    "3. A mystery **DNA methylation** dataset and a mystery **Gene Expression** dataset (for the final testing). In this dataset we don't say which tissue (or tissues) the samples come from so may be harder to classify the samples. Again the samples will have a label of either \"Solid Tissue Normal\" or \"Primary Tumour\"   \n",
    "\n",
    "#### As part of this problem you will need to think about the following:\n",
    "1. What method will you use to classify the samples (we provide a Neural Network example in the week 5 notebook)? This will require a short justification and a description of the method.\n",
    "2. What normalisation did you perform before putting the data through your model? Describe how you normalised each data type and why you normalised it in a certain way - plots would provide a sufficent justification here. Normalisation methods covered in week 6 were: standardising, min-max scaling, and log2 transformation\n",
    "3. How many features (i.e. genes or CpGs) is a sensible choice for each of your feature sets? What happens when you increase the number of genes or CpGs to your \"performance\"? Examples of feature selection could be: choosing X genes based on the literature, choosing the top X most variable genes, or the X genes with the largest log fold change. When considering the choice of X (e.g. number of genes or CpGs) think about the number of training examples you have.\n",
    "4. What is a good metric for \"performance\"? Is it \"accuracy\"? Or \"sensitivity\"? Or another metric? You will need to choose and justify this.\n",
    "5. How does each of your models perform on the mystery dataset? Why does it perform worse/better than on the dataset you used for training?\n",
    "\n",
    "### Dataset information\n",
    "\n",
    "1) breast = samples from the breast cancer cohort from TCGA (BRCA)  \n",
    "2) colon = samples from the colon cancer cohot from TCGA (COAD)  \n",
    "3) kidney = samples from the kidney cancer cohort from TCGA (KIRC)  \n",
    "4) liver = samples from the liver cancer cohort from TCGA (LIHC)  \n",
    "5) lung = samples from the lung cancer cohort from TCGA (LUAD)  \n",
    "\n",
    "The datasets labelled: dna-meth are the DNA methylation datasets and contain beta values for select CpG probes from the Illumina HumanMethylation450 BeadChip.\n",
    "The datasets labelled: gene-expr are the gene expression datasets and contain RPKM values for each gene.\n",
    "\n",
    "\n",
    "The columns of the dataset are the gene names followed by the entrez ID e.g. genename.entrezID (`AADAC.13`),  if the gene doesn't have a name it will be replaced by a dot (e.g. `..100130426` but you can still seach for the entrez id: e.g https://www.ncbi.nlm.nih.gov/gene/100130426). The first column of the dataset is the sample ID e.g. `TCGA.A3.3307.01` and the second column is the label e.g. `Primary Tumor`. The CpGs are labelled by their identifier which you can find information for in the provided annotation file: `CpG_hg19_annot.csv`.\n",
    "\n",
    "Datasets were downloaded from: http://acgt.cs.tau.ac.il/multi_omic_benchmark/download.html  \n",
    "\n",
    "Supplemental Papers:  \n",
    "https://www.nature.com/articles/s41467-020-20430-7  \n",
    "https://academic.oup.com/nar/article/46/20/10546/5123392  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: How-to install binfpy\n",
    "<a id='howto_install_binfpy'></a>\n",
    "\n",
    "\n",
    "The `binfpy` library is available from our local git server [GitLab_binfpy]. You can use git to store the binfpy directory on your computer where you can easily update it if any changes are made (see instructions below). You can also use the link to download the files in binfpy and place them in a folder of your choice. If any changes are made you will have to repeat the download process. **You will have to update your path regardless of which method you choose.**\n",
    "\n",
    "[GitLab_binfpy]: http://bioinf1.biosci.uq.edu.au/opensource/binfpy.git\n",
    "\n",
    "To install binfpy on your own computer, you need to have a git client installed on your computer or retrieve files from the web site above. \n",
    "\n",
    "**Mac OS X or Linux**\n",
    "\n",
    "If you're on Linux or Mac OS X, you should be set already. Open the terminal and change to a directory of choice and type \n",
    "```\n",
    "git clone http://bioinf1.biosci.uq.edu.au/opensource/binfpy.git\n",
    "```\n",
    "That will create a new directory called `binfpy` with a bunch of Python files.\n",
    "Add this directory, e.g. `/Users/johndoe/binfpy` to your PYTHONPATH, by adding the following line to your start-up file, e.g. `.profile`\n",
    "```\n",
    "export PYTHONPATH=/Users/johndoe/binfpy\n",
    "```\n",
    "This will be read next time you start a new shell, or you can activate immediately by \n",
    "```\n",
    "source .profile\n",
    "```\n",
    "\n",
    "**Windows**\n",
    "\n",
    "Install [git_for_windows]. Open the windows command prompt, navigate to a directory of your choice and type\n",
    "```\n",
    "git clone http://bioinf1.biosci.uq.edu.au/opensource/binfpy.git\n",
    "```\n",
    "That will create a new directory called `binfpy` with a bunch of Python files.\n",
    "Add this directory, e.g. `/Users/johndoe/binfpy` to your PYTHONPATH using the following instructions:\n",
    "\n",
    "Hit start and search for 'Environment variables'\n",
    "\n",
    "Add or edit the variable PYTHONPATH to include the `binfpy` directory\n",
    "\n",
    "[git_for_windows]: https://git-for-windows.github.io/\n",
    "\n",
    "**Updating**\n",
    "\n",
    "With all the above installed, you should be able to fire up your Python environment of choice, and `import` statements will be able to find the `binfpy` files. If there is an update, you can return to the binfpy directory and type\n",
    "```\n",
    "git pull\n",
    "```\n",
    "This will keep your files up-to-date. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
